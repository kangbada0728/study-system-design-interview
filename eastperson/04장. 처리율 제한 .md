# Overview

---

네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치다.

API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.

예시

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드(reward)를 요청할 수 없다.

장점

- DoS(Denial of Service) 공격에 의한 자원 고갈(resource starvation)을 방지할 수 있다.
    - 대형 IT 기업이 공개한 대부분의 API는 어떤 형태로든 처리율 제한 장치를 가지고 있다.
        
        [Usage limits  |  Google Docs  |  Google for Developers](https://developers.google.com/docs/api/limits)
        
- 비용 절감
    - 서버를 많이 두지 않아도 되고 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다.
    - third-party API에 사용료를 지불하고 있는 회사에게는 아주 중요하다. 횟수를 제한할 수 있어야 비용을 절감할 수 있다.
- 서버 과부하를 막는다.
    - 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치를 사용할 수 있다.

# 요구사항

- 서버 측에 제공되는 API
- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 성능
    - 낮은 응답시간
    - 가능한 한 적은 메모리 사용
- 다양한 형태의 제어 규칙(throttling role)을 정의할 수 있는 유연한 시스템
- 대규모 요청 처리
- 분산 환경에서 동작
    - 여러 서버나 프로세스에서 공유할 수 있어야 한다.
- 처리율 제한장치에 의해 걸러진 경우 사용자에게 전달
    - 예외처리하여 사용자에게 전달
- 높은 결함 감내성(fault tolerance)
    - 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.
 
# 설계안

서비스의 위치

- 처리율 제한 장치를 클라이언트에 두면 통제가 어려울 수 있다.
- 서버에 두면 안전정적으로 제한할 수 있다.
- 미들웨어(middleware)로 만들어서 통제할 수 있다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/2a7c33bb-d75f-4df1-8732-77f16d4e5120)

예외처리

- 429(Too many requests)를 클라이언트에 반환한다.

보통 마이크로서비스의 경우 처리율 제한 장치는 API 게이트웨이(gateway)에 구현된다. API 게이트웨이는 처리율 제한, SSL 종단(termination), 사용자 인증(authentication), IP 허용 목록(whitelist) 관리 등을 지원하는 완전 위탁관리형 서비스(fully managed) 서비스이다.

> 우리 회사에서는 CloudFlare로 IP Whitelist를 관리한다.

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘(token bucket)

- 널리 알려진 알고리즘이다.
    - 아마존과 스트라이프가 API 요청을 통제(throttle)하기 위해 사용한다.

**동작원리**

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/019d6643-1d95-480e-af1e-1ffa035eea6b)

토큰 버킷은 지정된 용량을 갖는 컨테이너다. 이 버킷에 사전 설정된 양의 토큰이 주기적으로 채워진다. 토큰이 꽉차면 더 이상의 토큰은 추가되지 않고 버려진다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/db205c29-e08b-4620-be58-d142975699df)

각 요청은 처리할 때마다 하나의 토큰을 사용한다. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다.

- 충분한 토큰이 있으면 버킷에서 토큰을 하나 꺼낸 후 요청을 시스템에 전달
- 충분한 토큰이 없는 경우 요청은 버려진다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/48e9f711-2c73-49bb-ad14-8059ad77760e)

- 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
- 토큰 공급률(refill rate): 초당 몇 개의 토큰이 버킷에 공급되는지

버킷의 사용은 공급 제한 규칙에 따라 달라진다.

- API 엔드포인트마다 별도의 버킷을 둬야한다.
    - 하루에 1번 포스팅, 친구는 150명까지 추가할 수 있고, 좋아요 버튼은 다섯번까지  등..
- IP 주소별로  처리율 제한을  적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 한다.
- 시스템의 처리율을 초당 10,000개 요청으로 제한하고 싶다면 모든 요청이 하나의 버킷을 공유하도록 해야한다.

장점

- 구현이 쉽다.
- 메모리 사용 측면에서 효율적이다.
- 짧은 시간에 집중되는 트래픽(burst of traffic) 처리 가능하다. 버킷에 남은 토큰이 있기만하면 요청은 시스템에 전달된다.

단점

- 버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데 이 값을 적절하게 튜닝하기가 어렵다.

### 누출 버킷 알고리즘(leaky bucket)

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다.
- 보통 FIFO 구현한다.

**동작원리**

1. 요청이 도착하면 큐가 가득차 있는지 본다. 빈자리가 있는 경우에 큐에 요청을 추가한다.
2. 큐가 가득 차 있는 경우에 새 요청은 버린다.
3. 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/8ea372fd-c69f-4d7d-bb90-ce262f8d3950)

**인자**

- 버킷 크기: 큐 사이즈와 같은 값. 큐에 처리될 항목들이 보관
- 처리율(outflow rate): 지정된 시간당 몇 개의 항목을 처리할 지 지정하는 값. 보통 초 단위로 표현.

장점

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다.
- 고정된 처리율을 갖고 있기 때문에 안정적 출력(stable outflow rate)이 필요한 경우에 적합하다.

단점

- 단시간에 많은 트래픽이 몰리는 경우 큐에 오래된 요청들이 쌓이게 되고 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.
- 두 개의 인자를 올바르게 튜닝하기 까다롭다.

### 고정 윈도 카운터(fixed window counter)

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/4d88e4d6-5028-45cf-b246-5f828a753e40)

동작원리

- 타임라인(timeline)을 고정된 간격의 윈도(window)로 나누고 각 윈도마다 카운터(counter)를 붙인다.
- 요청이 접수될 때마다 카운터의 값은 1씩 증가한다.
- 카운터의 값이 사전에 설정된 임계치(threshold)에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

장점

- 메모리 효율이 좋다.
- 이해하기 쉽다.
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합하다.

단점
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/08e4f412-8bcb-465f-8bdc-b70fcc6b05aa)
- 윈도 경계부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다.
    - 1분간 5개의 요청을 받는 윈도우지만 2:00:50 - 2:01:50 사이에 10개가 들어온다.

### 이동 윈도 로그(sliding window log)

위에나온 경계 부근에 트래픽이 몰리는 문제를 해결하는 방법이다.
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/b41efb4f-a8cc-4c42-a593-c60ca9a3b290)

동작원리

1. 타임스탬프(timestamp)를 추적한다. 타임스탬프 데이터는 보통 레디스의 sorted set 같은 캐시에 보관한다.
2. 새 요청이 오면 만료된 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.
3. 새 요청의 타임스탬프를 로그에 추가한다.
4. 로그의 크기나 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.

장점

- 매우 정교한 메커니즘이다.

단점

- 다량의 메모리를 사용한다
    - 거부된 요청의 타임스탬프도 보관하기 때문이다.

### 이동 윈도 카운터(sliding window counter)

고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다.
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/f08d074c-e2a1-4b6a-9fa4-518eced5c280)

분당 7개 요청이라고 할 때 이전 1분동안 5개 요청이, 현재 1분동안 3개 요청이 왔다고 했을 때, 1분의 30% 시점에 도착한 새 요청인 경우 어떻게 처리해야할까?

- 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율
    - 3 + 5 * 70% = 6.5개
    - 내림을 하면 6이므로 1개 추가 가능하다. 2개는 불가능하다.
        - 내림아니고 반울림해도 된다.

장점

- 메모리 효율이 좋다.
- 짧은 시간에 몰리는 트래픽에도 잘 대응한다.

단점

- 

## 레디스 예제

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/0aef354d-df17-4d5f-a90a-7cfe57eadc7f)

- INCR: 메모리에 저장된 카운터의 값을 1만큼 증가
- EXPIRE: 카운터에 타임아웃 값을 설정한다. 설정된 시간이 지나면 카운터는 자동으로 삭제된다.

동작원리

1. 클라이언트가 미들웨어에 요청을 보낸다.
2. 레디스의 지정 버킷에서 카운터를 가져와서 한도인지를 검사한다.
    1. 한도에 도달했으면 요청 거부
    2. 한도에 도달하지 않았으면 요청 API 서버로 돌리고 레디스의 카운트를 1 증가시킨다.

### Redis TTL Implementation

[How does redis expire keys?](https://stackoverflow.com/questions/36172745/how-does-redis-expire-keys)

1. 지연만료(semi-lazy)
    1. 지연 만료는 오브젝트를 읽을 때까지 실제로 오브젝트를 만료하지 않는다는 것을 의미합니다. 개체를 읽을 때 만료 타임스탬프를 확인하여 과거에 만료된 경우 아무것도 반환하지 않고 그 동안 개체를 삭제합니다. 하지만 문제는 키가 한 번도 건드리지 않으면 아무 이유 없이 메모리를 차지한다는 것입니다.
2. 활성 만료 계층
    1. 항상 임의의 키를 읽고 만료된 키가 터치되면 지연 메커니즘에 따라 삭제됩니다.
    2. 이는 만료 동작에 영향을 미치지 않으며 만료된 키의 "가비지 컬렉션"을 추가할 뿐입니다.

[EXPIRE](https://redis.io/commands/expire/)

[](https://github.com/antirez/redis/blob/a92921da135e38eedd89138e15fe9fd1ffdd9b48/src/expire.c#L98)

## 처리율 한도 초과 트래픽의 처리

- 요청 한도 제한에 걸리면 HTTP 429 응답(too many requests)을 클라이언트에게 보낸다.
- 클라이언트에게 헤더에 처리율 제한 메타데이터를 보내는 방법을 사용할 수 있다.
    - X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수
    - X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/26413f6b-a161-455c-b2be-0642bc8d882b)

- 버리는 요청을 메시지 큐에 보관해도 된다.

## 분산환경에서의 처리율 제한 장치 구현

두 가지 어려운 문제가 있다.
- 경쟁 조건(race condition)
    - 병행성이 심한 상황에서 문제가 발생할 수 있다.
    - 문제
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/9f1fcfd4-03fb-4316-a25b-f445c923aca8)
  - 레디스에서 카운터를 읽는다.
  - count+1의 값이 임계치를 넘는지 본다.
  - 넘지 않으면 레디스에 보관된 카운터 1을 증가시킨다.
- 경쟁조건 문제를 해결하기 위한 널리 알려진 해결책은 락(Lock)이다. 하지만 락은 시스템의 성능을 상당히 떨어뜨린다.
- 락 이외의 경쟁조건 해결방법
    - 루아 스크립트(Lua script)
    - Sorted Set
동기화(synchronization)
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/d9a53fd1-2a67-4c14-95e0-b2d88e9ee71b)
- 처리율 제한 장치를 여러개 둬야할 때 동기화가 필요하다.
- 웹 계층은 무상태이므로 클라이언트는 각기 다른 제한 장치로 보내게 될 수 있다. 하지만 동기하를 하지 않으면 제한 장치 1은 클라이언트 2에 대해서는 아무것도 모르므로 처리율 제한을 올바르게 수행할 수 없다.
- 이에 대한 해결책은 고정 세션(sticky session)을 활용하여 같은 클라이언트로부터 요청은 항상 같은 처리율 제한 장치로 보낼 수 있다.
- 더 나은 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/07f9f432-fc82-4cee-93a7-d3298bf14011)

## 성능 최적화

- 데이터센터 지원
    - 지연시간(latency)가 증가할 수 있다.
    - 대부분의 클라우드 사용자는에지서버를 심어놓고 있다.
- 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델(eventual consistency model)을 사용하느 ㄴ것이다.

## 모니터링

## 시간 기반 오류(time-based errors)

X분당 N개의 요청(maximum of N requests per X minutes)의 경우 기기에 과도한 부하가 발생하지 않도록 지수적 백오프를 사용하는 것이 좋다.

### 지수 백오프 알고리즘(exponential backoff algorithm)

네트워크 애플리케이션의 표준 오류 처리 전략이다. 지수 백오프 알고리즘은 최대 백오프 시간까지 요청 간 대기 시간을 기하급수적(1,2,4,8 …)으로 늘려 요청을 재시도합니다. 요청이 성공하지 못하면 성공할 때까지 요청간 지연이 증가하는 것이 중요하다.

[Usage limits  |  Google Docs  |  Google for Developers](https://developers.google.com/docs/api/limits#exponential)

## Request a quota increase

리소스 사용량에 따라 할당량 증가를 요청할 수 있다. 할당량 증가를 신청한다고 해서 승인이 보장되는 것은 아닙니다. 할당량을 크게 늘릴 경우 승인까지 시간이 오래 걸릴 수 있습니다.

# +Virtual Waiting Room

[Build a Virtual Waiting Room with Amazon DynamoDB and AWS Lambda at SeatGeek | Amazon Web Services](https://aws.amazon.com/blogs/architecture/build-a-virtual-waiting-room-with-amazon-dynamodb-and-aws-lambda-at-seatgeek/)

구매를 완료하기 위해 대기 중인 오버플로 고객을 별도의 대기열로 리디렉션하는 솔루션.

- 티켓팅, 수강신청 등에 쓰인다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/f46a36ed-1976-4be6-a958-57bdcf3682e5)

- 대기실 모드, 대기열 모드, 혼합 모드를 사용할 수 있다.

## 대기실 모드

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/dc8ff853-371d-4069-92fb-4a425bab700f)
대기실 모드에서는 지정된 판매 시작 시간 전에 이벤트 티켓팅 페이지에 대한 모든 요청이 별도의 화면으로 라우팅됩니다. 원하는 시간에 미리 정의된 처리 속도로 이벤트 페이지로 라우팅 된다.

## 대기열 모드
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/364740c6-0ddd-4a59-8390-614463ebc2a5)
대기 모드에서는 미리 설정한 수의 동시 사용자가 보호 영역에 액세스할 수 있도록 이벤트를 구성할 수 있습니다. 사전 설정된 수를 초과하는 사용자는 선입선출(FIFO) 대기열에서 대기합니다. 이벤트 코디네이터와 같은 예외 사용자는 관리 및 운영 가시성을 위해 대기열을 우회할 수 있습니다.
![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/7eabef8a-d227-4ac2-9fb6-8a0ba0afa45e)
경우에 따라 두 모드가 순차적으로 함께 작동할 수 있습니다. 이는 판매 시작 전에 대기실 모드를 사용한 후 대기열 모드로 전환하여 흐름을 제어할 때 발생할 수 있습니다.
고객이 대기열의 맨 앞으로 이동하면 보호 구역의 다음 줄에 서게 됩니다. 그림 5에 표시된 티켓 선택 페이지는 고객이 넘쳐나지 않도록 보호해야 하며, 이로 인해 초과 판매가 발생할 수 있습니다.

![image](https://github.com/kangbada0728/study-system-design-interview/assets/66561524/20168a69-1f16-4daa-9cad-f3126f1c7fba)

1. 고객이 콘서트 티켓과 같은 보호된 리소스를 요청하면 게이트 키퍼 애플리케이션이 해당 리소스에 활성 대기실이 있는지 검색합니다. 또한 고객에게 액세스 권한을 부여하기 위해 구성 규칙이 충족되는지 확인합니다. 어떤 이유로든 고객에게 보호된 리소스에 대한 액세스가 허용되지 않으면 해당 고객은 가상 대기실로 리디렉션됩니다.
2. 보호 구역 또는 대기실로 유입되는 사용자 흐름을 처리하는 바운서는 Amazon API 게이트웨이, AWS 람다, 토큰 서비스의 세 가지 구성 요소로 이루어져 있습니다. 
3. 토큰 서비스는 대기실 핵심 로직의 핵심입니다. 콘서트 이벤트 판매가 시작되기 전에 서버에서 생성되는 액세스 토큰의 수는 사용 가능한 티켓 수와 동일합니다. 대기실 고객에게 액세스 토큰을 할당하는 순서는 FIFO 또는 고객 상태(VIP 고객 우선)에 따라 달라질 수 있습니다. 토큰은 고객이 대기실에 입장할 때 할당되며 티켓을 구매하거나 고객이 퇴장할 때 만료됩니다.

[Virtual Waiting Room on AWS | AWS 솔루션](https://aws.amazon.com/ko/solutions/implementations/virtual-waiting-room-on-aws/)

[](http://www.isnt.co.kr/management/netfuunel/)

[에스티씨랩 | 넷퍼넬로 트래픽 관리하고 IT 인프라 비용 절감하기](https://www.stclab.com/netfunnel)

# Reference

[고 처리량 분산 비율 제한기](https://engineering.linecorp.com/ko/blog/high-throughput-distributed-rate-limiter)


