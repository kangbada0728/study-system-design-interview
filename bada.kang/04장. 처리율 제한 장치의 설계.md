---
tags:
  - 학습정리
  - SLiPP_25차_스터디
  - 시스템_설계
  - 책_가상_면접_사례로_배우는_대규모_시스템_설계_기초
  - 책_System_Design_Interview
---
# Intro

> [!note] 처리율 제한 장치란
> 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치

## 처리율 제한 장치를 두면 좋은점

- Dos(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있다.
- 추가 요청에 대한 처리를 제한하여 비용을 절감한다.
- 서버 과부하를 막는다.

# 1단계. 문제 이해 및 설계 범위 확정

- 어떤 종류의 처리율 제한 장치?
	- 서버측 API 를 위한 장치
- API 호출 제한 기준은?
	- 다양한 형태의 제어규칙 제어 필요
- 시스템 규모는?
	- 대규모 요청 처리 필요
- 분산환경?
	- 맞음
- 이 장치는 독립된 서비스? 아니면 애플리케이션 코드?
	- 그건 알아서
- 이 장치로 요청이 걸러지면 사용자에게 알림?
	- 해야함

이런식으로 핑퐁을 하면서 요구사항을 하나씩 맞춰가야 한다.


- 트위터가 API 제한을 하는 방식
	- 허용되는 최대 요청 수는 시간 간격, 지정된 기간 또는 기간을 기준
		-  가장 일반적인 요청 제한 간격은 15분
	- 사용 중인 인증 방법에 따라 속도 제한이 걸림
		- OAuth 1.0a 사용자 컨텍스트를 사용하는 경우, 각 사용자의 액세스 토큰 세트에 대해 기간당 하나의 제한
		- OAuth 2.0 베어러 토큰을 사용하는 경우, 앱의 요청에 대해 기간당 별도의 제한
		- ==왜 인증 방법에 따라 속도 제한이 걸릴까?==

# 2단계. 개략적 설계안 제시 및 동의 구하기

- 처리율 제한 장치는 어디에 둬야 할까?
	- 클라이언트에는 안두는 것이 위변조 방지에 좋음
	- 서버나 해당 장치를 놓을 미들웨어를 두는것이 좋음
	- ==미들웨어를 놓으면 애플리케이션에 직접 놓는것 보다 속도가 느리지 않을까? 속도 문제도 걱정==
	- 클라우드 마이크로서비스에서는 처리율 제한 장치는 API 게이트웨이 컴포넌트에 구현됨
		- 클라우드 업체가 유지 보수를 담당
		- ==이게 가장 좋아보이긴 한데 현재 회사에서는 비용문제 때문에 이런걸 안쓸것 같음 다른 회사에서는 어떨까?==
		- 

- 요청이 가로막히면 HTTP 상태 코드 429 를 반환
	- 구글에서도 그렇게 씀 [구글링크](https://developers.google.com/docs/api/limits?hl=ko)
	- 아마존도 마찬가지 [아마존링크](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html)

>[!note] 처리율 제한 장치 기능 만들때 참고할 수 있는 지침 2
>필요에 맞는 처리율 제한 알고리즘을 찾아라.

>[!note] 처리율 제한 장치 기능 만들때 참고할 수 있는 지침 1
>프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검하라. 현재 프로그래밍 언어가 서버 측 구현을 지원하기 충분할  정도로 효율이 높은지 확인하자.
>- ==다른 회사들은 이런 요청을 처리할 때 어떤 프로그래밍 언어를 쓸까? 자바는 불충분할까?==

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘

>[!note]
>토큰이 고정된 양까지 버킷에 사전 설정된 양으로 주기적으로 채워지고, API 요청 시마다 토큰이 하나씩 사라진다. 버킷에 토큰이 없으면 요청이 버려짐.

- 공급제한 규칙들
	- 일반적으로 API 엔드포인트마다 별도의 버킷을 둠.
		- 사용자 포스팅 개수 제어, 좋아요 버튼 제어 를 제어해야한다면 사용자마다 버킷을 3개 두는것임
	- IP 주소별로 처리율 제한을 할수도 있음
		- 그럼 IP 주소마다 버킷을 하나씩 둠
	- 시스템 처리율 자체를 통제하려면?
		- 모든 요청이 하나의 버킷을 공유하게 만듬

- 장점
	- 구현 쉬움
	- 메모리 사용이 효율적
	- 짧은 시간에 집중되는 트래픽도 처리 가능
- 단점
	- 버킷크기와 토큰 공급률이라는 두개의 인자를 튜닝하기 까다로움

### 누출 버킷

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있는 방식
- 보통 FIFO 로 구현된다.

- 요청이 오면 큐에 넣는다.
- 큐의 크기를 넘어서면 요청은 버림. 
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

- 사용하는 인자 크기
	- 버킷 크기 : 요청을 넣을 큐
	- 처리율 : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값

- 장점
	- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
	- 고정된 처리율을 갖고 있어 안정적 출력이 필요할 경우 좋음

- 단점
	- 단시간에 많은 트래픽이 몰리면 최신 요청은 버려지게 됨
	- 두 개의 인자를 갖고 있는데 튜닝하기 까다로움

### 고정 윈도 카운터

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다
- 요청이 접수될 때마다 카운터 값이 1씩 증가
- 카운터 값이 임계치에 도달하면 새로운 요청은 새 윈도가 열린때까지 버려짐

- 장점
	- 메모리 효율이 좋음
	- 이해하기 쉬움
	- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합

- 단점때문에 비추천
	- 윈도 경계부근에 트래픽이 몰리면 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있음

### 이동 윈도 로그

- 요청의 타임스탬프를 추적하며 타임스탬프를 캐시에 저장해놓는다.
	- 캐시는 보통 레디스의 정렬 집합 같은 것을 사용한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 제거 기준은 이번에 새로 온 요청의 타임스탬프에서 윈도 크기만큼 시간을 뺀 타임스탬프보다 빠른 요청들.
- 새 요청의 타임스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달. 그렇지 않으면 처리를 거부

- 장점
	- 처리율 제한 메커니즘이 매우 정교함
		- 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 못함

- 단점
	- 다량의 메모리 필요
		- 거부된 요청의 타임스탬프도 보관하기 때문


### 이동 윈도 카운터

구현방법 1

- 직전 1분간의 요청수 x 이동 윈도와 직전 1분이 겹치는 비율 + 현재 1분간의 요청 수
	- 고정된 윈도우들이 나열되어 있는 상황에서 새로 온 요청 타임스탬프를 기준으로 이동 윈도우를 그리는 것이다.
	- 그러면 이 이동 윈도우에서는 현재 1분의 윈도우에 포함되어 있는 영역도 있고, 직전 1분의 윈도우에 포함된 영역도 있을 것이다.
	- 이 영역들을 기준으로 계산을 하는 것이다.
- 이렇게 계산된 숫자가 처리율 제한 한도 보다 많으면 요청을 더 받지 않는다.

- ==질문 : 현재 1분간의 요청수는 어떻게 하는걸까? 현재시간이 현재 1분간의 요청 윈도우의 중간을 지날수도 있지 않은가==

- 장점
	- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하니까 짧은 시간에 몰리는 트패픽에 대응 잘한다.
	- 메모리 효율이 좋다.

- 단점
	- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.
		- 다만 심각한 문제는 아님. 자주 일어나지 않는 상황

## 개략적인 아키텍처

- 결국 처리율 제한장치는 카운터가 알파이자 오메가다.
- 알고리즘도 결국 카운터를 어떻게 처리할 것인가에 대한 내용뿐이다.

- 그럼 카운터는 어디다가 보관할까?
	- 속도가 빠른곳에 저장해야한다.
	- 메모리상에서 동작하는 캐시가 바람직하다.
	- 빠르고 시간에 기반한 만료정책을 지원하기 때문.
		- EX) 레디스






1. Rate-limiting strategies and technizues : https://cloud.google.com/architecture/infra-reliability-guide/traffic-load?hl=ko
2. Twitter rate limits : https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits
3. Google docs usage limits : https://developers.google.com/docs/api/limits?hl=ko
4. IBM microservices : https://www.ibm.com/topics/microservices
5. Throttle API requests for better throughput : https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html
6. Stripe rate limiters : https://stripe.com/blog/rate-limiters
7. Shopify REST Admin API rate limits : https://shopify.dev/docs/api/usage/rate-limits
8. Better Rate Limiting With Redis Sorted Sets : https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/
9. System Design - Rate limiter and Data modelling : https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling-9304b0d18250
10. How we built rate limiting capable of scaling to millions of domains : https://blog.cloudflare.com/counting-things-a-lot-of-different-things/
11. Redis website : https://redis.io
12. Lyft rate limiting : https://github.com/envoyproxy/ratelimit
13. Scaling your API with rate limiters : https://stripe.com/blog/rate-limiters
14. Wat is edge computing : https://www.cloudflare.com/ko-kr/learning/serverless/glossary/what-is-edge-computing/
15. Rate Limit Reqeusts with Iptables : https://blog.programster.org/rate-limit-requests-with-iptables
16. OSI model : https://en.wikipedia.org/wiki/OSI_model#Layer_architecture
