---
tags:
  - 학습정리
  - SLiPP_25차_스터디
  - 시스템_설계
  - 책_가상_면접_사례로_배우는_대규모_시스템_설계_기초
  - 책_System_Design_Interview
---
# Intro

> [!note] 처리율 제한 장치란
> 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치

## 처리율 제한 장치를 두면 좋은점

- Dos(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있다.
- 추가 요청에 대한 처리를 제한하여 비용을 절감한다.
- 서버 과부하를 막는다.

# 1단계. 문제 이해 및 설계 범위 확정

- 어떤 종류의 처리율 제한 장치?
	- 서버측 API 를 위한 장치
- API 호출 제한 기준은?
	- 다양한 형태의 제어규칙 제어 필요
- 시스템 규모는?
	- 대규모 요청 처리 필요
- 분산환경?
	- 맞음
- 이 장치는 독립된 서비스? 아니면 애플리케이션 코드?
	- 그건 알아서
- 이 장치로 요청이 걸러지면 사용자에게 알림?
	- 해야함

이런식으로 핑퐁을 하면서 요구사항을 하나씩 맞춰가야 한다.


- 트위터가 API 제한을 하는 방식
	- 허용되는 최대 요청 수는 시간 간격, 지정된 기간 또는 기간을 기준
		-  가장 일반적인 요청 제한 간격은 15분
	- 사용 중인 인증 방법에 따라 속도 제한이 걸림
		- OAuth 1.0a 사용자 컨텍스트를 사용하는 경우, 각 사용자의 액세스 토큰 세트에 대해 기간당 하나의 제한
		- OAuth 2.0 베어러 토큰을 사용하는 경우, 앱의 요청에 대해 기간당 별도의 제한
		- ==왜 인증 방법에 따라 속도 제한이 걸릴까?==

# 2단계. 개략적 설계안 제시 및 동의 구하기

- 처리율 제한 장치는 어디에 둬야 할까?
	- 클라이언트에는 안두는 것이 위변조 방지에 좋음
	- 서버나 해당 장치를 놓을 미들웨어를 두는것이 좋음
	- ==미들웨어를 놓으면 애플리케이션에 직접 놓는것 보다 속도가 느리지 않을까? 속도 문제도 걱정==
	- 클라우드 마이크로서비스에서는 처리율 제한 장치는 API 게이트웨이 컴포넌트에 구현됨
		- 클라우드 업체가 유지 보수를 담당
		- ==이게 가장 좋아보이긴 한데 현재 회사에서는 비용문제 때문에 이런걸 안쓸것 같음 다른 회사에서는 어떨까?==


- 요청이 가로막히면 HTTP 상태 코드 429 를 반환
	- 구글에서도 그렇게 씀 [구글링크](https://developers.google.com/docs/api/limits?hl=ko)
	- 아마존도 마찬가지 [아마존링크](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html)

>[!note] 처리율 제한 장치 기능 만들때 참고할 수 있는 지침 2
>필요에 맞는 처리율 제한 알고리즘을 찾아라.

>[!note] 처리율 제한 장치 기능 만들때 참고할 수 있는 지침 1
>프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검하라. 현재 프로그래밍 언어가 서버 측 구현을 지원하기 충분할  정도로 효율이 높은지 확인하자.
>- ==다른 회사들은 이런 요청을 처리할 때 어떤 프로그래밍 언어를 쓸까? 자바는 불충분할까?==

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘

>[!note]
>토큰이 고정된 양까지 버킷에 사전 설정된 양으로 주기적으로 채워지고, API 요청 시마다 토큰이 하나씩 사라진다. 버킷에 토큰이 없으면 요청이 버려짐.

- 공급제한 규칙들
	- 일반적으로 API 엔드포인트마다 별도의 버킷을 둠.
		- 사용자 포스팅 개수 제어, 좋아요 버튼 제어 를 제어해야한다면 사용자마다 버킷을 3개 두는것임
	- IP 주소별로 처리율 제한을 할수도 있음
		- 그럼 IP 주소마다 버킷을 하나씩 둠
	- 시스템 처리율 자체를 통제하려면?
		- 모든 요청이 하나의 버킷을 공유하게 만듬

- 장점
	- 구현 쉬움
	- 메모리 사용이 효율적
	- 짧은 시간에 집중되는 트래픽도 처리 가능
- 단점
	- 버킷크기와 토큰 공급률이라는 두개의 인자를 튜닝하기 까다로움

### 누출 버킷

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있는 방식
- 보통 FIFO 로 구현된다.

- 요청이 오면 큐에 넣는다.
- 큐의 크기를 넘어서면 요청은 버림. 
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

- 사용하는 인자 크기
	- 버킷 크기 : 요청을 넣을 큐
	- 처리율 : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값

- 장점
	- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
	- 고정된 처리율을 갖고 있어 안정적 출력이 필요할 경우 좋음

- 단점
	- 단시간에 많은 트래픽이 몰리면 최신 요청은 버려지게 됨
	- 두 개의 인자를 갖고 있는데 튜닝하기 까다로움

### 고정 윈도 카운터

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다
- 요청이 접수될 때마다 카운터 값이 1씩 증가
- 카운터 값이 임계치에 도달하면 새로운 요청은 새 윈도가 열린때까지 버려짐

- 장점
	- 메모리 효율이 좋음
	- 이해하기 쉬움
	- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합

- 단점때문에 비추천
	- 윈도 경계부근에 트래픽이 몰리면 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있음

### 이동 윈도 로그

- 요청의 타임스탬프를 추적하며 타임스탬프를 캐시에 저장해놓는다.
	- 캐시는 보통 레디스의 정렬 집합 같은 것을 사용한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 제거 기준은 이번에 새로 온 요청의 타임스탬프에서 윈도 크기만큼 시간을 뺀 타임스탬프보다 빠른 요청들.
- 새 요청의 타임스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달. 그렇지 않으면 처리를 거부

- 장점
	- 처리율 제한 메커니즘이 매우 정교함
		- 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 못함

- 단점
	- 다량의 메모리 필요
		- 거부된 요청의 타임스탬프도 보관하기 때문


### 이동 윈도 카운터

구현방법 1

- 직전 1분간의 요청수 x 이동 윈도와 직전 1분이 겹치는 비율 + 현재 1분간의 요청 수
	- 고정된 윈도우들이 나열되어 있는 상황에서 새로 온 요청 타임스탬프를 기준으로 이동 윈도우를 그리는 것이다.
	- 그러면 이 이동 윈도우에서는 현재 1분의 윈도우에 포함되어 있는 영역도 있고, 직전 1분의 윈도우에 포함된 영역도 있을 것이다.
	- 이 영역들을 기준으로 계산을 하는 것이다.
- 이렇게 계산된 숫자가 처리율 제한 한도 보다 많으면 요청을 더 받지 않는다.

- 장점
	- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하니까 짧은 시간에 몰리는 트패픽에 대응 잘한다.
	- 메모리 효율이 좋다.

- 단점
	- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.
		- 다만 심각한 문제는 아님. 자주 일어나지 않는 상황

## 개략적인 아키텍처

- 결국 처리율 제한장치는 카운터가 알파이자 오메가다.
- 알고리즘도 결국 카운터를 어떻게 처리할 것인가에 대한 내용뿐이다.

- 그럼 카운터는 어디다가 보관할까?
	- 속도가 빠른곳에 저장해야한다.
	- 메모리상에서 동작하는 캐시가 바람직하다.
	- 빠르고 시간에 기반한 만료정책을 지원하기 때문.
		- EX) 레디스

# 3단계. 상세 설계

## 처리율 제한 규칙

보통 설정파일 형태로 디스크에 저장된다.

## 처리율 한도 초과 트래픽의 처리

- 한도 제한이 걸리면 이단 HTTP 429 응답을 클라이언트에게 보낸다.
- 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수 도 있음
	- ex) 음식주문이 한도제한이 걸렸을때

### 처리율 제한 장치가 사용하는 HTTP 헤더

클라이언트에게 처리율 제한에 대해 알리고 관련 정보를 알리기 위해서 다음 헤더를 사용한다.

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수
- X-RateLimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

사용자가 너무 많은 요청을 보내면 429 오류를 X-RateLimit-Retry-After 헤더와 함께 반환하자.

==꼭 위 헤더를 다 보낼 필요는 없겠지?==

## 분산 환경에서의 처리율 제한 장치의 구현

여러 대의 서버와 병렬 스레드를 지원하도록 처리율 한도 초과 트래픽 시스템을 확장하려면 두가지 문제를 풀어야 한다.

- 경쟁조건
- 동기화

### 경쟁조건

카운터에 동시접근을 막아야 한다.

- 가장 간단한 방법은 Lock 을 거는 것이지만 시스템 성능을 떨어뜨린다.
- 레디스 정렬집합을 쓰는 것도 하나의 방법
	- 레디스 Sorted Set 은 중복되지 않는 데이터를 가지고 있으니까 이를 활용할 수 있다는 뜻이다.
	- 삽입삭제 모두 O(logN) 의 속도를 가져서 속도도 괜찮다.
	- ==그런데 이방법을 쓰면 사용할 수 있는 알고리즘에 제한이 생기지 않을까? 제일 대표적인 토큰버킷 알고리즘은 단순히 버킷 안의 토큰을 줄이는건데 레디스 Sorted Set 은 여기에서는 못쓸것 같다.==
- 루아 스크립트를 쓰는 것도 하나의 방법
	- ==혹시 따로 공부한 사람이 있을까? ==

### 동기화 이슈

- Sticky Session 은 로드벨런서에 부담을 주고 스케일아웃이 불가능하다.
- 레디스 같은 중앙 집중형 데이터 저장소를 쓰자.

### 성능 최적화

- 에지 서버를 다양한 지역에 심어놓는다.
- 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용한다.
	- 최종 일관성 모델 이란?
		- RDB(관계형 데이터베이스)는 동시성이라고 해서 같은 시간에 조회하는 데이터는 항상 동일한 데이터임을 보증하는걸 기본으로 한다.  
		- 그런데 NoSQL이 쓰이게 되면서 동시성을 더 이상 보장하기가 힘들어졌다.  
		- NoSQL은 분산 노드를 이용하여 그냥 무조건 빠른 데이터 처리가 주목적이기 때문이다.
		- 그래서 데이터 변경이 발생했을 때, 시간이 지남에 따라 여러 노드에 전파되면서 당장은 아니지만 최종적으로 일관성이 유지되는 것
		- 동시성을 제공하지 않고 결과적으로 일관성을 갖는다는 의미
	- ==버킷 동기화는 실시간으로 카운터가 전세계적으로 올라가야하지 않을까? 안그러면 접속하는 캐시에 따라서 매번 달라지지 않나? 이런 경우가 있지 않을까?==

### 모니터링

모니터링을 통해서 두가지를 확인하면 된다.

- 채택된 처리율 제한 알고리즘이 효과적인가
- 정의한 처리율 제한 규칙이 효과적인가

# 4단계. 마무리

추가로 알아보면 좋을 사항들

- 경성(hard) 또는 연성(soft) 처리율 제한
	- 경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘어설 수 없다.
	- 연성 처리율 제한 : 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
	- 이번장에서는 애플리케이션 계층에서의 처리율 제한에 대해서만 이야기했음
	- IP 주소에 처리율 제한을 적용하는 것이 가능
- 처리율 제한을 회피하는 방법. 클라리언트를 어떻게 설계하는 것이 최선인가
	- 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다.
	- 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구될 수 있도록 한다.
	- 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다.



1. Rate-limiting strategies and technizues : https://cloud.google.com/architecture/infra-reliability-guide/traffic-load?hl=ko
2. Twitter rate limits : https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits
3. Google docs usage limits : https://developers.google.com/docs/api/limits?hl=ko
4. IBM microservices : https://www.ibm.com/topics/microservices
5. Throttle API requests for better throughput : https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html
6. Stripe rate limiters : https://stripe.com/blog/rate-limiters
7. Shopify REST Admin API rate limits : https://shopify.dev/docs/api/usage/rate-limits
8. Better Rate Limiting With Redis Sorted Sets : https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/
9. System Design - Rate limiter and Data modelling : https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling-9304b0d18250
10. How we built rate limiting capable of scaling to millions of domains : https://blog.cloudflare.com/counting-things-a-lot-of-different-things/
11. Redis website : https://redis.io
12. Lyft rate limiting : https://github.com/envoyproxy/ratelimit
13. Scaling your API with rate limiters : https://stripe.com/blog/rate-limiters
14. Wat is edge computing : https://www.cloudflare.com/ko-kr/learning/serverless/glossary/what-is-edge-computing/
15. Rate Limit Reqeusts with Iptables : https://blog.programster.org/rate-limit-requests-with-iptables
16. OSI model : https://en.wikipedia.org/wiki/OSI_model#Layer_architecture
